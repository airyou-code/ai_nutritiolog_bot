import logging
import re
import asyncio
from typing import Dict, Any, Optional, List, Tuple
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, MessagesState, START, END

from bot.config.settings import settings
from bot.services.langgraph_service import langgraph_service

logger = logging.getLogger(__name__)


class FoodInputAnalysisState(MessagesState):
    """State for food input analysis"""
    user_input: str = ""
    is_food_related: bool = False
    analysis_type: str = ""  # "exact", "approximate", "need_clarification", "not_food"
    food_description: str = ""
    portion_info: Optional[str] = None
    analysis_confidence: float = 0.0


class FoodInputAgent:
    """Smart agent for analyzing user food input and determining response strategy"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=settings.openai_model,
            api_key=settings.openai_api_key,
            temperature=0.3,  # Lower temperature for more consistent analysis
        )
        self._input_analyzer = None
    
    async def get_input_analyzer(self):
        """Get or create food input analyzer"""
        if self._input_analyzer is None:
            self._input_analyzer = await self._create_input_analyzer()
            logger.info("Created food input analyzer agent")
        
        return self._input_analyzer
    
    async def _create_input_analyzer(self):
        """Create specialized agent for analyzing food input"""
        
        async def analyze_input_node(state: FoodInputAnalysisState):
            """Analyze user input to determine if it's food-related and extract info"""
            user_input = state.get("user_input", "")
            
            # First, quick regex check for obvious food patterns
            is_food_likely = self._quick_food_detection(user_input)
            
            if not is_food_likely:
                # Ask LLM for deeper analysis
                system_prompt = self._get_input_analysis_prompt()
                messages = [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ø–∏—Å–∞–ª: '{user_input}'")
                ]
                
                response = await self.llm.ainvoke(messages)
                analysis = self._parse_input_analysis(response.content)
            else:
                # Skip LLM call for obvious food input
                analysis = {
                    "is_food_related": True,
                    "analysis_type": self._determine_portion_type(user_input),
                    "food_description": user_input,
                    "portion_info": self._extract_portion_info(user_input),
                    "confidence": 0.9
                }
            
            return {
                **state,
                "is_food_related": analysis["is_food_related"],
                "analysis_type": analysis["analysis_type"],
                "food_description": analysis["food_description"],
                "portion_info": analysis.get("portion_info"),
                "analysis_confidence": analysis["confidence"]
            }
        
        # Build the graph
        workflow = StateGraph(FoodInputAnalysisState)
        workflow.add_node("analyzer", analyze_input_node)
        workflow.add_edge(START, "analyzer")
        workflow.add_edge("analyzer", END)
        
        return workflow.compile()
    
    def _quick_food_detection(self, text: str) -> bool:
        """Quick regex-based food detection"""
        text_lower = text.lower().strip()
        
        # First check for obvious NON-food patterns (reject immediately)
        non_food_patterns = [
            r'^(–ø—Ä–∏–≤–µ—Ç|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π|–¥–æ–±—Ä—ã–π –¥–µ–Ω—å|–¥–æ–±—Ä–æ–µ —É—Ç—Ä–æ|–¥–æ–±—Ä—ã–π –≤–µ—á–µ—Ä|hi|hello).*',
            r'^(–∫–∞–∫ –¥–µ–ª–∞|—á—Ç–æ –¥–µ–ª–∞–µ—à—å|–∫–∞–∫ –ø–æ–∂–∏–≤–∞–µ—à—å|–∫–∞–∫ –∂–∏–∑–Ω—å|—á—Ç–æ –Ω–æ–≤–æ–≥–æ).*',
            r'^(—Å–ø–∞—Å–∏–±–æ|–±–ª–∞–≥–æ–¥–∞—Ä—é|thanks|–ø–∞—Å–∏–±).*',
            r'^(–ø–æ–∫–∞|–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è|—É–≤–∏–¥–∏–º—Å—è|bye).*',
            r'^(–¥–∞|–Ω–µ—Ç|–Ω–µ –∑–Ω–∞—é|–º–æ–∂–µ—Ç –±—ã—Ç—å|–≤–æ–∑–º–æ–∂–Ω–æ)$',
            r'^(—Ö–æ—Ä–æ—à–æ|–ø–ª–æ—Ö–æ|–Ω–æ—Ä–º–∞–ª—å–Ω–æ|–æ—Ç–ª–∏—á–Ω–æ|–∫–ª–∞—Å—Å–Ω–æ|—É–∂–∞—Å–Ω–æ)$',
            r'^(–ø–æ–º–æ–≥–∏|–ø–æ–º–æ—â—å|—á—Ç–æ –¥–µ–ª–∞—Ç—å|–Ω–µ –ø–æ–Ω–∏–º–∞—é).*',
            r'^[!@#$%^&*()_+\-=\[\]{};\':"\\|,.<>\/?]*$',  # —Ç–æ–ª—å–∫–æ —Å–∏–º–≤–æ–ª—ã
        ]
        
        for pattern in non_food_patterns:
            if re.search(pattern, text_lower):
                return False
        
        # Common food-related keywords
        food_keywords = [
            # Meals
            '–∑–∞–≤—Ç—Ä–∞–∫', '–æ–±–µ–¥', '—É–∂–∏–Ω', '–ø–µ—Ä–µ–∫—É—Å', '—Å—ä–µ–ª', '–µ–ª', '–ø–æ–µ–ª',
            # Food types
            '—Å—É–ø', '–±–æ—Ä—â', '–∫–∞—à–∞', '—Å–∞–ª–∞—Ç', '–º—è—Å–æ', '–∫—É—Ä–∏—Ü–∞', '—Ä—ã–±–∞', '—Ö–ª–µ–±', 
            '–º–æ–ª–æ–∫–æ', '—Ç–≤–æ—Ä–æ–≥', '—Å—ã—Ä', '—è–π—Ü–æ', '–∫–∞—Ä—Ç–æ—Ñ–µ–ª—å', '—Ä–∏—Å', '–≥—Ä–µ—á–∫–∞',
            '–º–∞–∫–∞—Ä–æ–Ω—ã', '–ø–∞—Å—Ç–∞', '–ø–∏—Ü—Ü–∞', '–±—É—Ä–≥–µ—Ä', '—à–∞—É—Ä–º–∞', '—Ä–æ–ª–ª—ã',
            # Fruits/vegetables
            '–±–∞–Ω–∞–Ω', '—è–±–ª–æ–∫', '–∞–ø–µ–ª—å—Å–∏–Ω', '–≥—Ä—É—à', '–ø–æ–º–∏–¥–æ—Ä', '–æ–≥—É—Ä–µ—Ü', '–º–æ—Ä–∫–æ–≤—å',
            # Drinks
            '—á–∞–π', '–∫–æ—Ñ–µ', '—Å–æ–∫', '–º–æ–ª–æ–∫–æ', '–∫–µ—Ñ–∏—Ä', '–∫–æ–º–ø–æ—Ç',
            # Quantities
            '–≥—Ä–∞–º–º', '–∫–∏–ª–æ–≥—Ä–∞–º–º', '–ª–∏—Ç—Ä', '–º–∏–ª–ª–∏–ª–∏—Ç—Ä', '—à—Ç—É–∫', '–∫—É—Å–æ—á–µ–∫', '—Ç–∞—Ä–µ–ª–∫–∞',
            '—Å—Ç–∞–∫–∞–Ω', '—á–∞—à–∫–∞', '–ª–æ–∂–∫–∞', '–ø–æ—Ä—Ü–∏—è'
        ]
        
        # Check for food keywords
        for keyword in food_keywords:
            if keyword in text_lower:
                return True
        
        # Check for numbers + unit patterns (likely food with measurements)
        number_patterns = [
            r'\d+\s*–≥\b',  # –≥—Ä–∞–º–º—ã
            r'\d+\s*–∫–≥\b',  # –∫–∏–ª–æ–≥—Ä–∞–º–º—ã 
            r'\d+\s*–º–ª\b',  # –º–∏–ª–ª–∏–ª–∏—Ç—Ä—ã
            r'\d+\s*–ª\b',   # –ª–∏—Ç—Ä—ã
            r'\d+\s*—à—Ç\b',  # —à—Ç—É–∫–∏
            r'\d+\s*(–±–∞–Ω–∞–Ω|—è–±–ª–æ–∫|–æ–≥—É—Ä—Ü|–ø–æ–º–∏–¥–æ—Ä)',  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ—Ä—É–∫—Ç–æ–≤/–æ–≤–æ—â–µ–π
        ]
        
        for pattern in number_patterns:
            if re.search(pattern, text_lower):
                return True
        
        return False
    
    def _determine_portion_type(self, text: str) -> str:
        """Determine if portion is exact, approximate, or needs clarification"""
        text_lower = text.lower()
        
        # Exact portion indicators
        exact_patterns = [
            r'\d+\s*–≥\b',  # —Ç–æ—á–Ω—ã–π –≤–µ—Å –≤ –≥—Ä–∞–º–º–∞—Ö
            r'\d+\s*–∫–≥\b',  # —Ç–æ—á–Ω—ã–π –≤–µ—Å –≤ –∫–∏–ª–æ–≥—Ä–∞–º–º–∞—Ö
            r'\d+\s*–º–ª\b',  # —Ç–æ—á–Ω—ã–π –æ–±—ä–µ–º –≤ –º–ª
            r'\d+\s*–ª\b',   # —Ç–æ—á–Ω—ã–π –æ–±—ä–µ–º –≤ –ª–∏—Ç—Ä–∞—Ö
            r'\d+\s*(–±–∞–Ω–∞–Ω|—è–±–ª–æ–∫|–æ–≥—É—Ä—Ü|–ø–æ–º–∏–¥–æ—Ä|–∫—É—Å–æ—á–µ–∫|—à—Ç—É–∫)',  # —Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            r'(—Å—Ç–∞–∫–∞–Ω|—á–∞—à–∫–∞|—Ç–∞—Ä–µ–ª–∫–∞|–∫—Ä—É–∂–∫–∞|–±—É—Ç—ã–ª–∫–∞)\s+(–º–æ–ª–æ–∫–∞|–≤–æ–¥—ã|—Å–æ–∫–∞|—á–∞—è|–∫–æ—Ñ–µ|—Å—É–ø–∞|–±–æ—Ä—â–∞)',  # –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –µ–º–∫–æ—Å—Ç—å —Å –∂–∏–¥–∫–æ—Å—Ç—å—é
        ]
        
        # Check for exact patterns
        for pattern in exact_patterns:
            if re.search(pattern, text_lower):
                return "exact"
        
        # Size indicators that are approximate
        size_indicators = ['–º–∞–ª–µ–Ω—å–∫', '—Å—Ä–µ–¥–Ω', '–±–æ–ª—å—à', '–æ–≥—Ä–æ–º–Ω', '–∫—Ä–æ—à–µ—á–Ω']
        for indicator in size_indicators:
            if indicator in text_lower:
                return "approximate"
        
        # Very vague descriptions need clarification
        vague_patterns = [
            r'^(–µ–¥–∞|–±–ª—é–¥–æ|—á—Ç–æ-—Ç–æ|–Ω–µ–º–Ω–æ–≥–æ|—á—É—Ç—å-—á—É—Ç—å)$',
            r'^[–∞-—è—ë]{1,3}$',  # very short words
        ]
        
        for pattern in vague_patterns:
            if re.search(pattern, text_lower.strip()):
                return "need_clarification"
        
        # Default to approximate if it seems like food but no clear portion
        return "approximate"
    
    def _extract_portion_info(self, text: str) -> Optional[str]:
        """Extract portion information from text"""
        text_lower = text.lower()
        
        # Extract numbers with units
        patterns = {
            'weight': r'(\d+(?:\.\d+)?)\s*(–≥|–≥—Ä–∞–º|–≥—Ä|–∫–≥|–∫–∏–ª–æ–≥—Ä–∞–º–º)',
            'volume': r'(\d+(?:\.\d+)?)\s*(–º–ª|–º–∏–ª–ª–∏–ª–∏—Ç—Ä|–ª|–ª–∏—Ç—Ä)',
            'pieces': r'(\d+(?:\.\d+)?)\s*(—à—Ç|—à—Ç—É–∫|—à—Ç—É–∫–∏|–±–∞–Ω–∞–Ω|—è–±–ª–æ–∫|–æ–≥—É—Ä—Ü|–ø–æ–º–∏–¥–æ—Ä|–∫—É—Å–æ—á–µ–∫|–∫—É—Å–æ—á–∫–∞)',
            'containers': r'(—Å—Ç–∞–∫–∞–Ω|—á–∞—à–∫–∞|—Ç–∞—Ä–µ–ª–∫–∞|–∫—Ä—É–∂–∫–∞|–±—É—Ç—ã–ª–∫–∞|–º–∏—Å–∫–∞)',
            'sizes': r'(–º–∞–ª–µ–Ω—å–∫|—Å—Ä–µ–¥–Ω|–±–æ–ª—å—à|–æ–≥—Ä–æ–º–Ω|–∫—Ä–æ—à–µ—á–Ω)\w*'
        }
        
        extracted_info = []
        
        for category, pattern in patterns.items():
            matches = re.findall(pattern, text_lower)
            if matches:
                if category in ['weight', 'volume', 'pieces']:
                    for match in matches:
                        if isinstance(match, tuple):
                            extracted_info.append(f"{match[0]}{match[1]}")
                        else:
                            extracted_info.append(match)
                else:
                    extracted_info.extend(matches)
        
        return ", ".join(extracted_info) if extracted_info else None
    
    def _get_input_analysis_prompt(self) -> str:
        """Get prompt for input analysis"""
        return """
        –¢—ã —Å—Ç—Ä–æ–≥–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞ –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —É—á–µ—Ç–∞ –ø–∏—Ç–∞–Ω–∏—è.
        
        –ó–ê–î–ê–ß–ê: –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ö–û–ù–ö–†–ï–¢–ù–£–Æ –ï–î–£ –∏–ª–∏ –ë–õ–Æ–î–û.
        
        –û–ß–ï–ù–¨ –í–ê–ñ–ù–û: –û—Ç–∫–ª–æ–Ω—è–π –í–°–ï —á—Ç–æ –ù–ï —è–≤–ª—è–µ—Ç—Å—è –µ–¥–æ–π:
        - –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è: "–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å"
        - –í–æ–ø—Ä–æ—Å—ã: "–∫–∞–∫ –¥–µ–ª–∞", "—á—Ç–æ –¥–µ–ª–∞—Ç—å", "–ø–æ–º–æ–≥–∏"
        - –û–±—â–∏–µ —Ñ—Ä–∞–∑—ã: "—Å–ø–∞—Å–∏–±–æ", "–ø–æ–∫–∞", "–¥–∞", "–Ω–µ—Ç"
        - –≠–º–æ—Ü–∏–∏: "–∫–ª–∞—Å—Å–Ω–æ", "–ø–ª–æ—Ö–æ", "—Ö–æ—Ä–æ—à–æ"
        
        –ü–†–ò–ù–ò–ú–ê–ô —Ç–æ–ª—å–∫–æ –µ–¥—É:
        - –ù–∞–∑–≤–∞–Ω–∏—è –±–ª—é–¥: "–±–æ—Ä—â", "—Å–∞–ª–∞—Ç —Ü–µ–∑–∞—Ä—å", "–∫—É—Ä–∏–Ω–∞—è –≥—Ä—É–¥–∫–∞"
        - –ü—Ä–æ–¥—É–∫—Ç—ã: "–±–∞–Ω–∞–Ω", "–º–æ–ª–æ–∫–æ", "—Ö–ª–µ–±"
        - –° –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º: "2 —è–±–ª–æ–∫–∞", "—Å—Ç–∞–∫–∞–Ω –≤–æ–¥—ã", "—Ç–∞—Ä–µ–ª–∫–∞ —Å—É–ø–∞"
        
        –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ JSON:
        {
            "is_food_related": true/false,
            "analysis_type": "exact"/"approximate"/"need_clarification"/"not_food",
            "food_description": "–Ω–∞–∑–≤–∞–Ω–∏–µ –µ–¥—ã –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞",
            "portion_info": "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Ä—Ü–∏–∏ –∏–ª–∏ null",
            "confidence": 0.0-1.0,
            "reasoning": "–ø–æ—á–µ–º—É —ç—Ç–æ –µ–¥–∞ –∏–ª–∏ –Ω–µ –µ–¥–∞"
        }
        
        –¢–∏–ø—ã –∞–Ω–∞–ª–∏–∑–∞:
        - "exact": —Ç–æ—á–Ω—ã–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è (200–≥ –∫—É—Ä–∏—Ü—ã, 2 –±–∞–Ω–∞–Ω–∞, —Å—Ç–∞–∫–∞–Ω –º–æ–ª–æ–∫–∞)
        - "approximate": –Ω–µ—á–µ—Ç–∫–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è (–±–æ–ª—å—à–∞—è –ø–æ—Ä—Ü–∏—è, —Å–∞–ª–∞—Ç —Ü–µ–∑–∞—Ä—å)
        - "need_clarification": —Å–ª–∏—à–∫–æ–º –Ω–µ—è—Å–Ω–æ (–ø—Ä–æ—Å—Ç–æ "–µ–¥–∞", "—á—Ç–æ-—Ç–æ –≤–∫—É—Å–Ω–æ–µ")
        - "not_food": –ù–ï —Å–≤—è–∑–∞–Ω–æ —Å –µ–¥–æ–π (–ø—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞, —Å–ø–∞—Å–∏–±–æ)
        
        –í–ù–ò–ú–ê–ù–ò–ï: –ë—É–¥—å –æ—á–µ–Ω—å —Å—Ç—Ä–æ–≥–∏–º! –õ—É—á—à–µ –æ—Ç–∫–ª–æ–Ω–∏—Ç—å —Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–ª—É—á–∞–π.
        """
    
    def _parse_input_analysis(self, content: str) -> Dict[str, Any]:
        """Parse input analysis response"""
        try:
            import json
            start_idx = content.find('{')
            end_idx = content.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                raise ValueError("No JSON found")
            
            json_str = content[start_idx:end_idx]
            result = json.loads(json_str)
            
            return {
                "is_food_related": result.get("is_food_related", False),
                "analysis_type": result.get("analysis_type", "not_food"),
                "food_description": result.get("food_description", ""),
                "portion_info": result.get("portion_info"),
                "confidence": result.get("confidence", 0.0)
            }
            
        except Exception as e:
            logger.error(f"Error parsing input analysis: {e}")
            # Fallback to regex-based analysis
            text = content.lower()
            is_food = any(word in text for word in ['–µ–¥–∞', '–±–ª—é–¥–æ', '—Å—ä–µ–ª', '–ø–æ–µ–ª'])
            
            return {
                "is_food_related": is_food,
                "analysis_type": "approximate" if is_food else "not_food", 
                "food_description": content[:100],
                "portion_info": None,
                "confidence": 0.3
            }
    
    async def analyze_user_input(self, user_input: str) -> Dict[str, Any]:
        """Analyze user input and determine response strategy"""
        
        try:
            analyzer = await self.get_input_analyzer()
            
            # Create input state
            input_state = {
                "messages": [],
                "user_input": user_input.strip()
            }
            
            # Analyze input
            result = await analyzer.ainvoke(input_state)
            
            return {
                "is_food_related": result["is_food_related"],
                "analysis_type": result["analysis_type"],
                "food_description": result["food_description"],
                "portion_info": result["portion_info"],
                "confidence": result["analysis_confidence"],
                "original_input": user_input
            }
            
        except Exception as e:
            logger.error(f"Error analyzing user input: {e}")
            
            # Fallback analysis
            return {
                "is_food_related": False,
                "analysis_type": "not_food",
                "food_description": "",
                "portion_info": None,
                "confidence": 0.0,
                "original_input": user_input
            }
    
    async def process_food_input(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Process food input based on analysis type"""
        
        analysis_type = analysis["analysis_type"]
        food_description = analysis["food_description"]
        portion_info = analysis["portion_info"]
        
        try:
            if analysis_type == "exact":
                # For exact portions, analyze and create single option
                food_analysis = await langgraph_service.analyze_food_text_with_langgraph(
                    food_description, portion_info
                )
                # Ensure we have all required fields
                self._validate_food_analysis(food_analysis)
                return food_analysis
                
            elif analysis_type == "approximate":
                # For approximate descriptions, let AI generate multiple options
                food_analysis = await langgraph_service.analyze_food_text_with_langgraph(
                    food_description, portion_info
                )
                # Ensure we have all required fields
                self._validate_food_analysis(food_analysis)
                return food_analysis
                
            elif analysis_type == "need_clarification":
                # Ask for more details
                return {
                    "needs_clarification": True,
                    "food_name": "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –±–ª—é–¥–æ",
                    "description": f"–ù–∞ –æ—Å–Ω–æ–≤–µ: '{analysis['original_input']}'",
                    "portion_options": [],
                    "clarification_message": self._get_clarification_message(analysis["original_input"])
                }
            
            else:  # not_food
                return {
                    "not_food": True,
                    "message": "–Ø –Ω–µ —Å–º–æ–≥ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –±–ª—é–¥–æ –≤ —Ç–≤–æ–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏. –ü–æ–ø—Ä–æ–±—É–π –æ–ø–∏—Å–∞—Ç—å —á—Ç–æ —Ç—ã –µ–ª –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ."
                }
                
        except Exception as e:
            logger.error(f"Error processing food input: {e}")
            
            # Return not_food response on error
            return {
                "not_food": True,
                "message": f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å '{food_description}' –∫–∞–∫ –µ–¥—É. –ü–æ–ø—Ä–æ–±—É–π –æ–ø–∏—Å–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –±–ª—é–¥–æ."
            }
    
    def _validate_food_analysis(self, analysis: Dict[str, Any]) -> None:
        """Validate that food analysis has all required fields"""
        
        # Check if AI determined this is not food
        if analysis.get("is_food") == False:
            raise ValueError("AI determined this is not food")
        
        required_fields = ["food_name", "description", "portion_options", "nutrition_per_100g"]
        
        for field in required_fields:
            if field not in analysis:
                raise ValueError(f"Missing required field: {field}")
        
        # Check if food_name is empty or generic
        food_name = analysis.get("food_name", "").strip()
        if not food_name or food_name.lower() in ["–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –±–ª—é–¥–æ", "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –±–ª—é–¥–æ", "", "–∫–∞–∫ –¥–µ–ª–∞"]:
            raise ValueError("Invalid or empty food name")
        
        # Validate nutrition_per_100g structure
        nutrition = analysis["nutrition_per_100g"]
        required_nutrition_fields = ["calories", "protein", "fat", "carbs"]
        
        for field in required_nutrition_fields:
            if field not in nutrition:
                raise ValueError(f"Missing nutrition field: {field}")
        
        # Check if nutrition values are reasonable (not all zeros)
        total_nutrition = sum(nutrition.get(field, 0) for field in required_nutrition_fields)
        if total_nutrition == 0:
            raise ValueError("All nutrition values are zero - likely not food")
        
        # Validate portion_options structure
        if not isinstance(analysis["portion_options"], list) or len(analysis["portion_options"]) == 0:
            raise ValueError("portion_options must be a non-empty list")
    
    def _get_clarification_message(self, original_input: str) -> str:
        """Get clarification message for unclear input"""
        return f"""
ü§î –ú–Ω–µ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π!

–¢—ã –Ω–∞–ø–∏—Å–∞–ª: "{original_input}"

–ü–æ–ø—Ä–æ–±—É–π –æ–ø–∏—Å–∞—Ç—å –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ:
‚Ä¢ –ß—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—ã –µ–ª?
‚Ä¢ –ö–∞–∫–∞—è –±—ã–ª–∞ –ø–æ—Ä—Ü–∏—è?

**–ü—Ä–∏–º–µ—Ä—ã —Ö–æ—Ä–æ—à–µ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è:**
‚Ä¢ "2 –±–∞–Ω–∞–Ω–∞"
‚Ä¢ "—Ç–∞—Ä–µ–ª–∫–∞ –±–æ—Ä—â–∞"
‚Ä¢ "–∫—É—Å–æ—á–µ–∫ —Ö–ª–µ–±–∞"
‚Ä¢ "—Å—Ç–∞–∫–∞–Ω –º–æ–ª–æ–∫–∞"
‚Ä¢ "—Å–∞–ª–∞—Ç —Ü–µ–∑–∞—Ä—å –±–æ–ª—å—à–∞—è –ø–æ—Ä—Ü–∏—è"
"""


# Global service instance
food_input_agent = FoodInputAgent() 