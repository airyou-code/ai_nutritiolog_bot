import logging
import asyncio
import json
import base64
from io import BytesIO
from typing import Dict, Any, AsyncGenerator, Optional, List, Callable
from datetime import date

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.checkpoint.memory import MemorySaver
# TODO: Add Redis checkpointer when properly configured
# from langgraph_checkpoint_redis import RedisCheckpointer
from langgraph.prebuilt import create_react_agent
from PIL import Image

from bot.config.settings import settings
from bot.services.redis_service import redis_service
from bot.database.connection import get_db_session
from bot.database.operations.food_ops import get_user_daily_nutrition_summary

logger = logging.getLogger(__name__)


class LangGraphService:
    """Service for LangGraph-based AI conversations and agents"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=settings.openai_model,
            api_key=settings.openai_api_key,
            temperature=0.7,
            streaming=True
        )
        self._checkpointer = None
        self._nutrition_agent = None
        self._food_analysis_agent = None
    
    async def get_checkpointer(self):
        """Get checkpointer for conversation memory"""
        if self._checkpointer is None:
            try:
                # TODO: Implement Redis checkpointer when properly configured
                # For now, use memory-based checkpointer
                logger.info("Using in-memory checkpointer for LangGraph conversations")
                self._checkpointer = MemorySaver()
            except Exception as e:
                logger.error(f"Error creating checkpointer: {e}")
                self._checkpointer = MemorySaver()
        
        return self._checkpointer
    
    async def save_important_conversation_data(
        self,
        user_id: int,
        conversation_summary: str,
        insights: Dict[str, Any],
        nutrition_goals: Optional[Dict] = None
    ):
        """Save important conversation insights to PostgreSQL for long-term storage"""
        
        try:
            # This would be implemented to save key insights to database
            # For example: dietary preferences, allergies, goals, etc.
            
            logger.info(f"Saving conversation insights for user {user_id}")
            
            # Example structure for future implementation:
            conversation_data = {
                "user_id": user_id,
                "summary": conversation_summary,
                "insights": insights,
                "nutrition_goals": nutrition_goals,
                "timestamp": asyncio.get_event_loop().time()
            }
            
            # TODO: Implement database storage
            # await save_conversation_insights(conversation_data)
            
        except Exception as e:
            logger.error(f"Error saving conversation data: {e}")
    
    async def get_user_conversation_context(self, user_id: int) -> Dict[str, Any]:
        """Get user's conversation context from both Redis and PostgreSQL"""
        
        context = {
            "recent_topics": [],
            "preferences": {},
            "long_term_goals": {},
            "conversation_style": "friendly"
        }
        
        try:
            # Get recent conversation topics from Redis
            recent_data = await redis_service.get_temp_data(user_id, "recent_topics")
            if recent_data:
                context["recent_topics"] = recent_data
            
            # TODO: Get long-term preferences from PostgreSQL
            # long_term_data = await get_user_conversation_preferences(user_id)
            # context.update(long_term_data)
            
        except Exception as e:
            logger.error(f"Error loading conversation context: {e}")
        
        return context
    
    async def get_nutrition_agent(self):
        """Get or create nutrition consultant agent"""
        if self._nutrition_agent is None:
            checkpointer = await self.get_checkpointer()
            
            # Create specialized nutrition agent
            self._nutrition_agent = await self._create_nutrition_agent(checkpointer)
            logger.info("Created nutrition consultant agent")
        
        return self._nutrition_agent
    
    async def _create_nutrition_agent(self, checkpointer):
        """Create a specialized nutrition consultant agent"""
        
        # Define the agent's state and behavior
        class NutritionState(MessagesState):
            user_id: Optional[int] = None
            nutrition_data: Optional[Dict] = None
            context_loaded: bool = False
        
        async def load_user_context(state: NutritionState):
            """Load user's nutrition data for context"""
            if state.get("context_loaded", False):
                return state
            
            user_id = state.get("user_id")
            if not user_id:
                return {**state, "context_loaded": True}
            
            try:
                async with get_db_session() as session:
                    today = date.today()
                    nutrition_data = await get_user_daily_nutrition_summary(session, user_id, today)
                    
                    return {
                        **state, 
                        "nutrition_data": nutrition_data,
                        "context_loaded": True
                    }
            except Exception as e:
                logger.error(f"Error loading user context: {e}")
                return {**state, "context_loaded": True}
        
        async def nutrition_consultant(state: NutritionState):
            """Main nutrition consultant node"""
            messages = state["messages"]
            nutrition_data = state.get("nutrition_data")
            
            # Build system prompt with user context
            system_prompt = self._build_nutrition_system_prompt(nutrition_data)
            
            # Prepare messages for LLM
            llm_messages = [SystemMessage(content=system_prompt)]
            llm_messages.extend(messages)
            
            # Get response from LLM
            response = await self.llm.ainvoke(llm_messages)
            
            return {"messages": [response]}
        
        # Build the graph
        workflow = StateGraph(NutritionState)
        
        # Add nodes
        workflow.add_node("load_context", load_user_context)
        workflow.add_node("consultant", nutrition_consultant)
        
        # Define flow
        workflow.add_edge(START, "load_context")
        workflow.add_edge("load_context", "consultant")
        workflow.add_edge("consultant", END)
        
        # Compile with checkpointer
        return workflow.compile(checkpointer=checkpointer)
    
    def _build_nutrition_system_prompt(self, nutrition_data: Optional[Dict] = None) -> str:
        """Build system prompt for nutrition consultant"""
        
        base_prompt = """
        –¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –Ω—É—Ç—Ä–∏—Ü–∏–æ–ª–æ–≥ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø–∏—Ç–∞–Ω–∏—é. 
        
        –¢–≤–æ–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:
        - –î–∞–≤–∞–π –Ω–∞—É—á–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–≤–µ—Ç—ã
        - –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
        - –ë—É–¥—å –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–º –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º
        - –£—á–∏—Ç—ã–≤–∞–π –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        - –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –≤—Ä–∞—á—É
        
        –¢—ã –º–æ–∂–µ—à—å –ø–æ–º–æ—á—å —Å:
        - –ê–Ω–∞–ª–∏–∑–æ–º —Ä–∞—Ü–∏–æ–Ω–∞ –ø–∏—Ç–∞–Ω–∏—è
        - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –ø–∏—Ç–∞–Ω–∏—è
        - –û—Ç–≤–µ—Ç–∞–º–∏ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –ë–ñ–£ –∏ –∫–∞–ª–æ—Ä–∏—è—Ö
        - –°–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º –ø–ª–∞–Ω–æ–≤ –ø–∏—Ç–∞–Ω–∏—è
        - –°–æ–≤–µ—Ç–∞–º–∏ –ø–æ –∑–¥–æ—Ä–æ–≤–æ–º—É –æ–±—Ä–∞–∑—É –∂–∏–∑–Ω–∏
        """
        
        if nutrition_data and nutrition_data.get('entries_count', 0) > 0:
            base_prompt += f"""
            
        –î–∞–Ω–Ω—ã–µ –æ –ø–∏—Ç–∞–Ω–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–µ–≥–æ–¥–Ω—è:
        - –û–±—â–∏–µ –∫–∞–ª–æ—Ä–∏–∏: {nutrition_data.get('total_calories', 0):.1f} –∫–∫–∞–ª
        - –ë–µ–ª–∫–∏: {nutrition_data.get('total_protein', 0):.1f} –≥
        - –ñ–∏—Ä—ã: {nutrition_data.get('total_fat', 0):.1f} –≥
        - –£–≥–ª–µ–≤–æ–¥—ã: {nutrition_data.get('total_carbs', 0):.1f} –≥
        - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–µ–º–æ–≤ –ø–∏—â–∏: {nutrition_data.get('entries_count', 0)}
        
        –£—á–∏—Ç—ã–≤–∞–π —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.
        """
        
        return base_prompt
    
    async def chat_with_nutrition_agent(
        self,
        user_message: str,
        user_id: int,
        thread_id: Optional[str] = None
    ) -> AsyncGenerator[str, None]:
        """Chat with nutrition agent and stream response"""
        
        try:
            agent = await self.get_nutrition_agent()
            
            # Prepare config for conversation thread
            config = {
                "configurable": {
                    "thread_id": thread_id or f"user_{user_id}_{int(asyncio.get_event_loop().time())}"
                }
            }
            
            # Create input state
            input_state = {
                "messages": [HumanMessage(content=user_message)],
                "user_id": user_id,
                "context_loaded": False
            }
            
            # Stream response from agent
            async for event in agent.astream(input_state, config=config, stream_mode="updates"):
                for node_name, node_output in event.items():
                    if node_name == "consultant" and "messages" in node_output:
                        message = node_output["messages"][-1]
                        if hasattr(message, 'content'):
                            # Yield content in chunks for streaming effect
                            content = message.content
                            chunk_size = 50
                            for i in range(0, len(content), chunk_size):
                                chunk = content[i:i + chunk_size]
                                yield chunk
                                await asyncio.sleep(0.1)  # Small delay for streaming effect
                            break
                    
        except Exception as e:
            logger.error(f"Error in nutrition agent chat: {e}")
            yield f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"
    
    async def simple_chat_stream(
        self,
        user_message: str,
        system_prompt: Optional[str] = None,
        nutrition_data: Optional[Dict] = None
    ) -> AsyncGenerator[str, None]:
        """Simple streaming chat without complex agent logic"""
        
        try:
            # Build messages
            messages = []
            
            if system_prompt:
                messages.append(SystemMessage(content=system_prompt))
            else:
                messages.append(SystemMessage(content=self._build_nutrition_system_prompt(nutrition_data)))
            
            messages.append(HumanMessage(content=user_message))
            
            # Stream response
            async for chunk in self.llm.astream(messages):
                if chunk.content:
                    yield chunk.content
                    
        except Exception as e:
            logger.error(f"Error in simple chat stream: {e}")
            yield f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"
    
    async def analyze_conversation_context(
        self,
        messages: List[BaseMessage],
        user_id: int
    ) -> Dict[str, Any]:
        """Analyze conversation context to determine best response strategy"""
        
        # Simple context analysis - can be extended with more sophisticated logic
        last_message = messages[-1].content.lower() if messages else ""
        
        context = {
            "is_food_related": any(word in last_message for word in [
                '–µ–¥–∞', '–±–ª—é–¥–æ', '–∫–∞–ª–æ—Ä–∏–∏', '–±–µ–ª–∫–∏', '–∂–∏—Ä—ã', '—É–≥–ª–µ–≤–æ–¥—ã', 
                '—Ä–∞—Ü–∏–æ–Ω', '–ø–∏—Ç–∞–Ω–∏–µ', '–¥–∏–µ—Ç–∞', '–≤–µ—Å', '–ø–æ—Ö—É–¥–µ—Ç—å'
            ]),
            "is_personal_question": any(word in last_message for word in [
                '–º–æ–π', '–º–Ω–µ', '—è', '–º–æ–∏', '–º–µ–Ω—è'
            ]),
            "needs_nutrition_data": any(word in last_message for word in [
                '—Å–µ–≥–æ–¥–Ω—è', '–¥–Ω–µ–≤–Ω–∏–∫', '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', '–ø—Ä–æ–≥—Ä–µ—Å—Å'
            ]),
            "is_greeting": any(word in last_message for word in [
                '–ø—Ä–∏–≤–µ—Ç', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π', '–¥–æ–±—Ä–æ', '–Ω–∞—á–∞—Ç—å'
            ])
        }
        
        return context
    
    async def analyze_food_photo_with_langgraph(
        self,
        image_data: bytes,
        user_description: Optional[str] = None
    ) -> Dict[str, Any]:
        """Analyze food photo using LangGraph agent"""
        
        try:
            # Create specialized food analysis agent
            food_agent = await self._create_food_analysis_agent()
            
            # Convert image to base64
            image = Image.open(BytesIO(image_data))
            
            # Resize image if too large to save tokens
            max_size = (1024, 1024)
            if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                image.thumbnail(max_size, Image.Resampling.LANCZOS)
            
            # Convert to RGB if necessary
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Convert to base64
            buffer = BytesIO()
            image.save(buffer, format='JPEG', quality=85)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            # Create prompt for food analysis
            prompt = self._get_food_analysis_prompt(user_description)
            
            # Create input with image
            input_state = {
                "messages": [HumanMessage(content=[
                    {
                        "type": "text",
                        "text": prompt
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}"
                        }
                    }
                ])],
                "image_data": image_base64,
                "user_description": user_description
            }
            
            # Process with agent
            result = await food_agent.ainvoke(input_state)
            
            # Parse the response
            response_content = result["messages"][-1].content
            return self._parse_food_analysis_response(response_content)
            
        except Exception as e:
            logger.error(f"Error analyzing food photo with LangGraph: {e}")
            raise
    
    async def analyze_food_text_with_langgraph(
        self,
        food_description: str,
        portion_info: Optional[str] = None
    ) -> Dict[str, Any]:
        """Analyze food text using LangGraph agent"""
        
        try:
            # Create specialized food analysis agent
            food_agent = await self._create_food_analysis_agent()
            
            # Create prompt for text analysis
            prompt = self._get_text_analysis_prompt(food_description, portion_info)
            
            # Create input
            input_state = {
                "messages": [HumanMessage(content=prompt)],
                "food_description": food_description,
                "portion_info": portion_info
            }
            
            # Process with agent
            result = await food_agent.ainvoke(input_state)
            
            # Parse the response
            response_content = result["messages"][-1].content
            return self._parse_food_analysis_response(response_content)
            
        except Exception as e:
            logger.error(f"Error analyzing food text with LangGraph: {e}")
            raise
    
    async def _create_food_analysis_agent(self):
        """Create specialized food analysis agent"""
        
        if self._food_analysis_agent is None:
            # Define specialized state for food analysis
            class FoodAnalysisState(MessagesState):
                image_data: Optional[str] = None
                user_description: Optional[str] = None
                food_description: Optional[str] = None
                portion_info: Optional[str] = None
            
            async def food_analyzer_node(state: FoodAnalysisState):
                """Specialized node for food analysis"""
                messages = state["messages"]
                
                # Create specialized LLM for food analysis with specific temperature
                food_llm = ChatOpenAI(
                    model=settings.openai_model,
                    api_key=settings.openai_api_key,
                    temperature=0.3,  # Lower temperature for more consistent analysis
                    max_tokens=1000
                )
                
                # Get response from LLM
                response = await food_llm.ainvoke(messages)
                
                return {"messages": [response]}
            
            # Build the graph
            workflow = StateGraph(FoodAnalysisState)
            workflow.add_node("analyzer", food_analyzer_node)
            workflow.add_edge(START, "analyzer")
            workflow.add_edge("analyzer", END)
            
            # Compile without checkpointer (stateless for food analysis)
            self._food_analysis_agent = workflow.compile()
            logger.info("Created specialized food analysis agent")
        
        return self._food_analysis_agent
    
    def _get_food_analysis_prompt(self, user_description: Optional[str] = None) -> str:
        """Get prompt for food photo analysis"""
        
        base_prompt = """
        –¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —É—á–µ—Ç–∞ –ø–∏—Ç–∞–Ω–∏—è.
        
        –ó–ê–î–ê–ß–ê: –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –µ–¥—É –Ω–∞ —Ñ–æ—Ç–æ –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –µ—ë.
        
        –ï–°–õ–ò –ù–ê –§–û–¢–û –û–ß–ï–í–ò–î–ù–û –ù–ï –ï–î–ê (–ª—é–¥–∏, –ø–µ–π–∑–∞–∂–∏, –º–µ–±–µ–ª—å, –∂–∏–≤–æ—Ç–Ω—ã–µ –±–µ–∑ –µ–¥—ã), –≤–µ—Ä–Ω–∏:
        {
            "is_food": false,
            "food_name": "",
            "description": "–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –µ–¥–∞",
            "portion_options": [],
            "nutrition_per_100g": {"calories": 0, "protein": 0, "fat": 0, "carbs": 0}
        }
        
        –ï–°–õ–ò –ù–ê –§–û–¢–û –ï–°–¢–¨ –ï–î–ê (—Ñ—Ä—É–∫—Ç—ã, –æ–≤–æ—â–∏, –±–ª—é–¥–∞, –Ω–∞–ø–∏—Ç–∫–∏), –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π:
        {
            "is_food": true,
            "food_name": "–Ω–∞–∑–≤–∞–Ω–∏–µ –±–ª—é–¥–∞",
            "description": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–∞",
            "portion_options": [
                {"size": "exact", "weight": –≤–µ—Å_–≤_–≥—Ä–∞–º–º–∞—Ö, "description": "—Ç–æ—á–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ—Ä—Ü–∏–∏"}
            ],
            "nutrition_per_100g": {
                "calories": –∫–∞–ª–æ—Ä–∏–∏_–Ω–∞_100–≥,
                "protein": –±–µ–ª–∫–∏_–Ω–∞_100–≥,
                "fat": –∂–∏—Ä—ã_–Ω–∞_100–≥,
                "carbs": —É–≥–ª–µ–≤–æ–¥—ã_–Ω–∞_100–≥
            }
        }
        
        –õ–æ–≥–∏–∫–∞ –¥–ª—è portion_options:
        - –ï—Å–ª–∏ –¢–û–ß–ù–û –≤–∏–¥–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ (2 –±–∞–Ω–∞–Ω–∞, 1 —è–±–ª–æ–∫–æ, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Ç–∞—Ä–µ–ª–∫–∞) ‚Üí –û–î–ò–ù –≤–∞—Ä–∏–∞–Ω—Ç
        - –ï—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ù–ï–û–ü–†–ï–î–ï–õ–ï–ù–ù–û ‚Üí 2-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º
        
        –í–ê–ñ–ù–û: –ë–∞–Ω–∞–Ω, —è–±–ª–æ–∫–æ, –æ–≤–æ—â–∏ - —ç—Ç–æ –ï–î–ê! –û—Ç–∫–ª–æ–Ω—è–π —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–æ—á–Ω–æ –ù–ï –µ–¥–∞.
        """
        
        if user_description:
            base_prompt += f"\n\n–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_description}"
        
        return base_prompt
    
    def _get_text_analysis_prompt(self, food_description: str, portion_info: Optional[str] = None) -> str:
        """Get prompt for text food analysis"""
        
        prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–ø–∏—Å–∞–Ω–∏–µ –±–ª—é–¥–∞ –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:

        –ë–ª—é–¥–æ: {food_description}
        """
        
        if portion_info:
            prompt += f"\n–ü–æ—Ä—Ü–∏—è: {portion_info}"
        
        prompt += """

        –°–ù–ê–ß–ê–õ–ê –ø—Ä–æ–≤–µ—Ä—å - —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ –ï–î–´?
        
        –ï–°–õ–ò –ù–ï –ï–î–ê (–æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã, –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è, –≤–æ–ø—Ä–æ—Å—ã), –≤–µ—Ä–Ω–∏:
        {
            "is_food": false,
            "food_name": "",
            "description": "–≠—Ç–æ –Ω–µ –æ–ø–∏—Å–∞–Ω–∏–µ –µ–¥—ã",
            "portion_options": [],
            "nutrition_per_100g": {"calories": 0, "protein": 0, "fat": 0, "carbs": 0}
        }
        
        –ï–°–õ–ò –≠–¢–û –ï–î–ê, –≤–µ—Ä–Ω–∏:
        {
            "is_food": true,
            "food_name": "–Ω–∞–∑–≤–∞–Ω–∏–µ –±–ª—é–¥–∞",
            "description": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–∞",
            "portion_options": [
                {"size": "exact", "weight": –≤–µ—Å_–≤_–≥—Ä–∞–º–º–∞—Ö, "description": "—Ç–æ—á–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ"}
            ],
            "nutrition_per_100g": {
                "calories": –∫–∞–ª–æ—Ä–∏–∏_–Ω–∞_100–≥,
                "protein": –±–µ–ª–∫–∏_–Ω–∞_100–≥,
                "fat": –∂–∏—Ä—ã_–Ω–∞_100–≥,
                "carbs": —É–≥–ª–µ–≤–æ–¥—ã_–Ω–∞_100–≥
            }
        }
        
        –õ–û–ì–ò–ö–ê –¥–ª—è portion_options:
        
        üéØ –¢–û–ß–ù–û–ï –ö–û–õ–ò–ß–ï–°–¢–í–û (–¥–∞–π 1 –≤–∞—Ä–∏–∞–Ω—Ç):
        - "2 –±–∞–Ω–∞–Ω–∞" ‚Üí [{"size": "exact", "weight": 240, "description": "2 –±–∞–Ω–∞–Ω–∞"}]
        - "3 —è–±–ª–æ–∫–∞" ‚Üí [{"size": "exact", "weight": 450, "description": "3 —Å—Ä–µ–¥–Ω–∏—Ö —è–±–ª–æ–∫–∞"}]
        - "—Ç–∞—Ä–µ–ª–∫–∞ —Å—É–ø–∞" ‚Üí [{"size": "exact", "weight": 300, "description": "—Ç–∞—Ä–µ–ª–∫–∞ —Å—É–ø–∞"}]
        - "—Å—Ç–∞–∫–∞–Ω –º–æ–ª–æ–∫–∞" ‚Üí [{"size": "exact", "weight": 250, "description": "—Å—Ç–∞–∫–∞–Ω –º–æ–ª–æ–∫–∞"}]
        - "–∫—É—Å–æ—á–µ–∫ —Ö–ª–µ–±–∞" ‚Üí [{"size": "exact", "weight": 30, "description": "–∫—É—Å–æ—á–µ–∫ —Ö–ª–µ–±–∞"}]
        
        ‚ùì –ù–ï–û–ü–†–ï–î–ï–õ–ï–ù–ù–û–ï –ö–û–õ–ò–ß–ï–°–¢–í–û (–¥–∞–π 2-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞):
        - "–±–∞–Ω–∞–Ω" ‚Üí [
            {"size": "small", "weight": 120, "description": "1 –±–∞–Ω–∞–Ω"},
            {"size": "medium", "weight": 240, "description": "2 –±–∞–Ω–∞–Ω–∞"},
            {"size": "large", "weight": 360, "description": "3 –±–∞–Ω–∞–Ω–∞"}
          ]
        - "—è–±–ª–æ–∫–æ" ‚Üí –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É (–º–∞–ª–µ–Ω—å–∫–æ–µ/—Å—Ä–µ–¥–Ω–µ–µ/–±–æ–ª—å—à–æ–µ)
        - "—Å—É–ø" ‚Üí –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É (–ø–æ–ª—Ç–∞—Ä–µ–ª–∫–∏/—Ç–∞—Ä–µ–ª–∫–∞/–±–æ–ª—å—à–∞—è –ø–æ—Ä—Ü–∏—è)
        - "—Ç–æ—Ä—Ç" ‚Üí –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É –∫—É—Å–∫–∞
        
        –í–ù–ò–ú–ê–ù–ò–ï: –°—Ç—Ä–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä—É–π –ù–ï-–ï–î–£. –õ—É—á—à–µ –æ—Ç–∫–ª–æ–Ω–∏—Ç—å —Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–µ.
        """
        
        return prompt
    
    def _parse_food_analysis_response(self, content: str) -> Dict[str, Any]:
        """Parse food analysis response"""
        
        try:
            # Try to extract JSON from response
            start_idx = content.find('{')
            end_idx = content.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                raise ValueError("No JSON found in response")
            
            json_str = content[start_idx:end_idx]
            return json.loads(json_str)
            
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"Error parsing food analysis response: {e}")
            logger.error(f"Response content: {content}")
            
            # Return default structure if parsing fails  
            return {
                "is_food": False,
                "food_name": "",
                "description": "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ - –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –±–ª—é–¥–æ",
                "portion_options": [],
                "nutrition_per_100g": {
                    "calories": 0,
                    "protein": 0,
                    "fat": 0,
                    "carbs": 0
                }
            }


# Global service instance
langgraph_service = LangGraphService()
